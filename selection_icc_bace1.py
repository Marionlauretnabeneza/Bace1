# -*- coding: utf-8 -*-
"""Selection Icc BACE1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z_1FlVTJ2qE8AzWkXTEkrx32RjQR_fIw
"""

pip install scanpy

pip install we-get

pip install you-get

pip install plotly

pip install mdtraj

pip install biopython pandas

pip install mdtraj pandas

pip install pytest

pip install mdtraj pandas requests

pip install parmed

pip install gemmi

#from google.colab import drive
#drive.mount('/content/drive')

import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt
import statsmodels.sandbox.stats.multicomp as sm
from scipy.stats import spearmanr
import scanpy as sc
import anndata
import plotly.express as px
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
import seaborn as sns
import mdtraj as md
import pandas as pd
import gemmi
import requests
from io import StringIO
import tempfile
import os
from tkinter import Tk, filedialog
import os
import shutil

"""1/ Données CSV from RSCB
filtered on
  1) Résolution
  2) Poids moléculaires
  3) Binding Affinity
"""

df = pd.read_csv(r"/content/(1)rcsb_pdb_custom_report.csv")
df.drop(df.index[:0], inplace=True)
# Remplacer les noms de colonnes par la première ligne
df.columns = df.iloc[0]

# Supprimer la première ligne qui contenait les anciens noms de colonnes
df = df[1:]

# Réindexer le DataFrame après la suppression de la première ligne
df.reset_index(drop=True, inplace=True)
df.set_index(df.columns[0], inplace=True)
df = df.dropna(subset=['Resolution (Å)'])
df.head(2)

df6=df.T
df6['5MCQ']

#1) extraire les données en fonction de leur résolution Å <2, WM,

# Convertir la colonne 'Resolution (Å)' en nombres
df['Resolution (Å)'] = pd.to_numeric(df['Resolution (Å)'], errors='coerce')
df['Ligand MW'] = pd.to_numeric(df['Ligand MW'], errors='coerce')
df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
df['Number of Water Molecules per Deposited Model'] = pd.to_numeric(df['Number of Water Molecules per Deposited Model'])


dfseuil= df[['Resolution (Å)','Number of Water Molecules per Deposited Model']]
dfseuil.head()
dfseuil = dfseuil.dropna()

dfseuil= df[['Resolution (Å)','Number of Water Molecules per Deposited Model']]
dfseuil.head()
dfseuil = dfseuil.dropna()
# Détermination du Seuil de résolution optimale par rapport au nombre de molécules d'eau
X = dfseuil[['Resolution (Å)']].values
y = dfseuil['Number of Water Molecules per Deposited Model'].values

# Initialiser le modèle de régression linéaire
model = LinearRegression()

# Ajuster le modèle aux données
model.fit(X, y)

# Prédire la quantité d'eau en fonction de la variable A
predictions = model.predict(X)

# Tracer le graphique de la régression linéaire
plt.scatter(X, y, color='lightblue', label='Données')
plt.plot(X, predictions, color='red', label='Régression linéaire')
plt.xlabel('Variable A')
plt.ylabel('Quantité d\'eau')
plt.title('Régression Linéaire entre Variable A et Quantité d\'eau')
plt.legend()
plt.show()

len(df)

"""2) Sélectionné en fonction du pénalty

Parser en fonction des paramètres
  - df = total
  - Résolution : df1 = df[df['Resolution (Å)'] <= 2]
  - Poids moléculaires : df2 = df1[df1['Ligand MW'] >= 400]
  - Bindind valeur df3 = df2[(df2['Value'] >= 0) & (df2['Value'] <= 10)]

Grâce à cette liste, on va parser on va sélectionner les 10 échantillons, extraire les fichiers prm des complexes et obtenir une liste de ces échantillons classés selon la fréquence de pénalité la plus faible. Enfin on sélectionnera 5 des premiers éléments que l'on réorganisera selon leur poids moléuclaire le plus élevé. Pour finaliser la sélection, une analyse de la composition en résidus du ligand sera faite pour sélectionner le complexe qui aura la meilleure stabilité.
"""

# Filtrer les lignes où la colonne 'Resolution (Å)' est inférieure ou égale à 2
df1 = df[df['Resolution (Å)'] <= 2]
df2 = df1[df1['Ligand MW'] >= 400]
df3 = df2[(df2['Value'] >= 0) & (df2['Value'] <= 10)]
print(" on a"  ,len(df)," initialement")
print(" on a"  ,len(df1)," qui ont une résolution inférieure à 2Å")
print(" on a ",len(df2)," qui ont le poids moléculaire est supérieure ou égale à 400kDa")
print(" on a " ,len(df3), " qui ont une valeur de binding comprise entre 0 et 10")

df3.sort_values(by='Ligand MW', ascending=False)

# Liste des codes PDB
pdb_codes = df3.index

element = "5MCQ"
if element in df2.index:
    print(f"L'élément {element} est présent dans la colonne d'index.")
else:
    print(f"L'élément {element} n'est pas présent dans la colonne d'index.")

"""LISTE des fichiers .prm en input"""

liste_fichiers = ['/content/2IQG.prm',
                  '/content/2VNM.prm',
                  '/content/2VNN.prm',
                  '/content/2XFK.prm',
                  '/content/3CIC.prm',
                  '/content/3CID.prm',
                  '/content/4DI2.prm',
                  '/content/4GID.prm',
                  '/content/2G94.prm']
df3['prm_penalty %']=None

"""TEST de calcul de la fréquence de pénalité

*   2IQG
*   Élément de liste


"""

# Chemin du fichier
chemin_fichier = '/content/2IQG.prm'

with open(chemin_fichier, 'r') as fichier:
      # Lire le contenu du fichier et stocker chaque ligne dans une liste
  lignes = fichier.readlines()

# Créer un DataFrame à partir de la liste de lignes
df5 = pd.DataFrame(lignes, columns=['Contenu'])

# Afficher le DataFrame
df5.head(4)

# Créer une colonne qui correspond au parsing du %penalty
df5['Nouvelle_Colonne'] = df5['Contenu'].str.extract(r' penalty= (.*)', expand=False)
df5['Nouvelle_Colonne'] = pd.to_numeric(df5['Nouvelle_Colonne'], errors='coerce')


# Calculer la fréquence de pénalty pour chaque complexe
Nb = 0
pen = 0

for i in df5['Nouvelle_Colonne']:
    if i >= 0:
        Nb = Nb + 1
    if i < 50:
        pen = pen + 1

# Éviter la division par zéro
if Nb != 0:
    Freq_penalty = pen / Nb
    print("Freq_penalty = ",Freq_penalty,"%")
else:
    print("/content/2IQG.prm}Division par zéro évitée. Nb est égal à zéro.")

"""Calcule de la fréquence de pénalité pour chaque fichier.prm"""

def calculer_freq_penalty(df_colonne):
    Nb = 0
    pen = 0

    for i in df_colonne:
        if i >= 0:
            Nb += 1

        # si somme des %pen >10 /Total %pen <20% on a un seuil de pénalité bas.
        if i > 10:
            pen += 1
    print(pen)
    # Éviter la division par zéro
    if Nb != 0:
        Freq_penalty = pen / Nb
        return Freq_penalty
    else:
        print("Division par zéro évitée. Nb est égal à zéro.")
        return 0  # Return 0 instead of None

def trouver_index_par_chemin(df, chemin):
    # Extraire le nom du fichier du chemin
    ID = chemin.split('/')[-1].split('.')[0]
    print(ID)

    # Trouver l'index correspondant au nom du fichier dans la colonne 'Nom_Fichier'
    index = df3.index[df3.index == ID].tolist()
    if index:
        return index[0]
    else:
        print(f"Le fichier {ID} n'a pas été trouvé dans la colonne 'Nom_Fichier' du DataFrame.")
        return None

# Chemin du fichier
chemin_fichier = liste_fichiers

# Initialiser une liste pour stocker les fréquences
freq_penalty_data = []

# Lire chaque fichier et calculer la fréquence de pénalité
for fichier in liste_fichiers:
    #Ouvrir le fichier.prm
    with open(fichier, 'r') as file:
        lignes = file.readlines()

    # Créer un DataFrame pour le fichier actuel : df_freq = fichier d'où l'on calcule la fréquence de pénalité du complexe
    df_freq = pd.DataFrame(lignes, columns=['Contenu'])
    df_freq['Nouvelle_Colonne'] = df_freq['Contenu'].str.extract(r' penalty= (.*)', expand=False)
    df_freq['Nouvelle_Colonne'] = pd.to_numeric(df_freq['Nouvelle_Colonne'], errors='coerce')
    df_freq['Nouvelle_Colonne'] = df_freq['Nouvelle_Colonne'].astype(float)

    # Calcul de la fréquence de penalty
    freq_penalty_result = calculer_freq_penalty(df_freq['Nouvelle_Colonne'])

    # Trouver l'index correspondant dans le DataFrame principal df
    index = trouver_index_par_chemin(df, fichier)

    if index is not None:
        if freq_penalty_result is not None:
            print(freq_penalty_result)
            # Ajouter les données de freq_penalty à la liste
            freq_penalty_data.append({'Nom_Fichier': index, 'Freq_Penalty': freq_penalty_result * 100})

            print(f"Fréquence Penalty pour {index} : {freq_penalty_result * 100}%")
        else:
            print("La fréquence de pénalité est None, ne pas ajouter à la liste.")

import matplotlib.pyplot as plt
from matplotlib import cm

# Filtrer les lignes où la colonne 'Resolution (Å)' est inférieure ou égale à 2
df1 = df[df['Resolution (Å)'] <= 2]
df2 = df1[df1['Ligand MW'] >= 400]
df3 = df2[(df2['Value'] >= 0) & (df2['Value'] <= 10)]
# Parseuer en fonction de la fréquence de pénalty
penalty = pd.DataFrame(freq_penalty_data)
penalty.set_index('Nom_Fichier', inplace=True)

for i in df3.index:
    if i in penalty.index:
        df3.loc[i, 'Freq_penalty'] = penalty.loc[i, 'Freq_Penalty']
    else:
        df3.loc[i, 'Freq_penalty'] = None

df4 = df3[(df3['Freq_penalty'] >= 0) & (df3['Freq_penalty'] <= 20)]

# Transformer la colonne 'Freq_penalty' en données numériques
df4['Freq_penalty'] = pd.to_numeric(df4['Freq_penalty'], errors='coerce')

# Assurez-vous que la colonne est de type numérique
df4['Freq_penalty'] = df4['Freq_penalty'].astype(float)

# Tri par ordre décroissant en fonction de 'Freq_penalty' et qui ont un poids moléculaire >500
df5 = df4.sort_values(by='Ligand MW', ascending=True)

# Créer un graphique à barres pour visualiser les variations de la longueur des DataFrames
noms_des_groupes = ['Total', 'Résolution <= 2Å',' MW >=400 ', 'Affinity [5-10]nM', 'penalty <20%']
valeurs_des_groupes = [len(df), len(df1),len(df2),len(df3),len(df4)]

fig, ax = plt.subplots()

# Utiliser une colormap de bleu
couleurs = cm.Blues([0.2, 0.4, 0.6, 0.8, 1.0,1,2])

# Ajouter les barres au graphique avec le dégradé de couleur bleu
bars = ax.bar(noms_des_groupes, valeurs_des_groupes, color=couleurs)

# Ajouter des valeurs au-dessus de chaque barre
for bar, valeur in zip(bars, valeurs_des_groupes):
    height = bar.get_height()
    ax.annotate(f'{valeur}', xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),  # 3 points de décalage vers le haut
                textcoords="offset points",
                ha='center', va='bottom')

# Mettre en diagonale les éléments de la légende
plt.xticks(rotation=45)

# Ajouter des titres et des labels
plt.title('Selection du ligand optimal de BACE1 en fonction des paramètres')
plt.ylabel('Nombre de ligand ID')

# Récupérer le chemin complet du bureau
bureau_path = os.path.join(os.path.expanduser("~"), "Desktop")

# Afficher le graphique
plt.show()

print('nombre Total=',len(df))
print('nombre filtré pour Résolution <= 2Å=',len(df1))
print('nombre filtré pour MW >= 400=',len(df2))
print('nombre filtré pour Affinité [5-10]nM=',len(df3))
print('nombre filtré pour Penalty < 20%=',len(df4))
print('nombre filtré pour Top high MW',len(df5))
print('la sélection Top high MW est ', df5.index)

# Spécifiez le chemin du fichier CSV
chemin_csv = "Top_selection_BACE1.csv"

# Exportez le DataFrame en fichier CSV
df5.to_csv(chemin_csv, index=False)

# Spécifiez le chemin de destination pour le téléchargement
chemin_destination = "/Content"

# Copiez simplement le fichier vers le chemin de destination
shutil.copy(chemin_csv, chemin_destination)
# Affichez un message indiquant que le fichier CSV a été créé et téléchargé
print(f"Le DataFrame a été exporté dans {chemin_csv}")
print(f"Le fichier a été copié vers {chemin_destination}")
